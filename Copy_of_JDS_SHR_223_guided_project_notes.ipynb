{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobinCross/RobinCross/blob/main/Copy_of_JDS_SHR_223_guided_project_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhphDysw-6P"
      },
      "source": [
        "## BloomTech Data Science\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvWhcow-dvS8"
      },
      "source": [
        "# Cross-Validation\n",
        "\n",
        "- Do **k-fold cross-validation** with independent test set\n",
        "- Use scikit-learn for **hyperparameter optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgkCSgGdty-"
      },
      "source": [
        "%%capture\n",
        "!pip install category_encoders==2.*"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF70Jp0x4NJU"
      },
      "source": [
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score, validation_curve # k-fold CV\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # Hyperparameter tuning\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVzQtNC9oucF"
      },
      "source": [
        "# Downloading the Tanzania Waterpump Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-olXlnJoucR"
      },
      "source": [
        "Make sure  you only use the dataset that is available through the **DS** **Kaggle Competition**. DO NOT USE any other Tanzania waterpump datasets that you might find online.\n",
        "\n",
        "There are two ways you can get the dataset. Make sure you have joined the competition first!:\n",
        "\n",
        "1. You can download the dataset directly by accessing the challenge and the files through the Kaggle Competition URL on Canvas (make sure you have joined the competition!)\n",
        "\n",
        "2. Use the Kaggle API using the code in the following cells. This article provides helpful information on how to fetch your Kaggle Dataset into Google Colab using the Kaggle API.\n",
        "\n",
        "> https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6TZ5nDFYkCa"
      },
      "source": [
        "# Using Kaggle API to download datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2e6fPUATxLZ",
        "outputId": "b8cb2a8b-707c-4da8-e5b6-ff9b88f48493"
      },
      "source": [
        "# mounting your google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYSpUv9uYBAo",
        "outputId": "2e6a88bf-6b0b-4a8e-aeac-e0919d4a78fb"
      },
      "source": [
        "#change your working directory, if you want to or have already saved your kaggle dataset on google drive.\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "# update it to your folder location on drive that contians the dataset and/or kaggle API token json file."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXChvgdZYb_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c80f239-52aa-41f0-d2ba-cc853db2a071"
      },
      "source": [
        "#Download your Kaggle Dataset, if you haven't already done so.\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "!kaggle competitions download -c bloomtech-water-pump-challenge"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /content/gdrive/My Drive/Kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB84qgRRYdDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98208215-d4ad-4c98-cf12-382ddc7c25cc"
      },
      "source": [
        "# Unzip your Kaggle dataset, if you haven't already done so.\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eag2zYiQYf6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb86c8d-56e5-4456-a185-4115351add64"
      },
      "source": [
        "# List all files in your Kaggle folder on your google drive.\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data  test_features.csv\ttrain_features.csv  train_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBYPw7kd1AN"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaXMenXoZ0D6"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "  if tv_path:\n",
        "    df = pd.merge(pd.read_csv(fm_path,\n",
        "                              na_values=[0, -2.000000e-08],\n",
        "                              parse_dates=['date_recorded']),\n",
        "                  pd.read_csv(tv_path)).set_index('id')\n",
        "  else:\n",
        "    df = pd.read_csv(fm_path,\n",
        "                     na_values=[0, -2.000000e-08],\n",
        "                     parse_dates=['date_recorded'],\n",
        "                     index_col='id')\n",
        "\n",
        "  # Drop constant columns\n",
        "  df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "  # Create age feature\n",
        "  df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "  df.drop(columns='date_recorded', inplace=True)\n",
        "\n",
        "  # Drop HCCCs\n",
        "  cutoff = 100\n",
        "  drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "              if df[col].nunique() > cutoff]\n",
        "  df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "  # Drop duplicate columns\n",
        "  dupe_cols = [col for col in df.head(100).T.duplicated().index # change 15 to 100!!!!\n",
        "               if df.head(100).T.duplicated()[col]]\n",
        "  df.drop(columns=dupe_cols, inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "df = wrangle(fm_path='train_features.csv',\n",
        "             tv_path='train_labels.csv')\n",
        "\n",
        "X_test = wrangle(fm_path='test_features.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wupyZysm_avz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04aa6a58-dc22-41b1-a0d3-9c93b9abe721"
      },
      "source": [
        "df.shape, X_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47519, 31), (11880, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jetWccxMqmzY"
      },
      "source": [
        "# II. Split Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MPA0qlr-mK"
      },
      "source": [
        "## Split TV from FM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'status_group'\n",
        "y = df[target]\n",
        "X = df.drop(columns = target)"
      ],
      "metadata": {
        "id": "-iN01DozUbyH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8jSWomGsLsw"
      },
      "source": [
        "# Training-Validation Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9uvMMgs6J_"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "This is a **classification** problem, our baseline will be **accuracy**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts(normalize = True).max()"
      ],
      "metadata": {
        "id": "PkUJVqSuULDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafcd7dd-e52b-4292-ff01-6ceebf82059a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5429828068772491"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA19NsrFtgTT"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "- `DecisionTreeClassifier`\n",
        "- `RandomForestClassifier`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ZpJSwObNl_"
      },
      "source": [
        "model_dt = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    DecisionTreeClassifier(random_state=42))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4fO6aXEbNiQ"
      },
      "source": [
        "model_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(n_estimators =25, random_state=42)\n",
        ");"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l96Atv4REyH3"
      },
      "source": [
        "**Check cross-validation scores**\n",
        "\n",
        "![Cross Validation](https://upload.wikimedia.org/wikipedia/commons/4/4b/KfoldCV.gif)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kfold_cv = Kfold(n_splits=5, shuffle =True, random_state=42)\n",
        "cv_scores_dt = cross_val_score(model_dt, X, y, cv=5, n_jobs=-1)\n",
        "cv_scores_rf = cross_val_score(model_rf, X, y, cv=5, n_jobs=-1)"
      ],
      "metadata": {
        "id": "ccjKqllNEh_u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLx-EHNGB-xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fed8336-f5a9-4e2c-9927-16024ce24b25"
      },
      "source": [
        "print('CV score DecisionTreeClassifier',cv_scores_dt)\n",
        "print('Mean CV accuracy score:',cv_scores_dt.mean() )\n",
        "print('STD CV accuracy score:',cv_scores_dt.std())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score DecisionTreeClassifier [0.74400253 0.75210438 0.74915825 0.74957912 0.7465011 ]\n",
            "Mean CV accuracy score: 0.7482690762017027\n",
            "STD CV accuracy score: 0.002776529048546816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLIdbPJpCC_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c0fd6c-1d3a-4c2a-9247-76dd445aac12"
      },
      "source": [
        "print('CV score RandomForestClassifier', cv_scores_rf)\n",
        "print('Mean CV accuracy score:',cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:',cv_scores_rf.std())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score RandomForestClassifier [0.79292929 0.79703283 0.79819024 0.79882155 0.79385457]\n",
            "Mean CV accuracy score: 0.7961656955928502\n",
            "STD CV accuracy score: 0.002354562865226338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSTF3aOWo-5-"
      },
      "source": [
        "# V. Tune Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcYCO2Cj4ILg"
      },
      "source": [
        "Different hyperparameter values I want to try out :\n",
        "\n",
        "*   Simpleimputer - mean, median - 2 values\n",
        "*   max_depth - range(5,40,5) - 7 values\n",
        "*   n_estimators - range(25,125,25) - 4 values\n",
        "\n",
        "> Total combinations of these hyperparameters = 2 * 7 * 4 = 56\n",
        "\n",
        "Testing out the above hyperparameter combinations with 5-fold Cross Validation will need :\n",
        "\n",
        "> Total number of models to be fit = 2 * 7 * 4 * 5 = 280\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1))"
      ],
      "metadata": {
        "id": "LgK-doeJWMAE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'SimpleImputer__strategy':['mean','median'],\n",
        "    'RandomForestClassifier__max_depth':range(5,40,5),\n",
        "    'RandomForestClassifier__n_estimators': range(25,125,25),\n",
        "}"
      ],
      "metadata": {
        "id": "jrMYSoldWL7l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRL-I2ensgom"
      },
      "source": [
        "**`GridSearch`:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_valid_params = clf.named_steps['randomforestclassifier'].get_params().keys()\n",
        "\n",
        "# Example usage to print the valid parameters\n",
        "print(f\"Valid parameters are: {list(local_valid_params)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mf4fGpILC6p",
        "outputId": "67590a2c-a438-44a8-f34d-beeeb28504f4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf_gs = GridSearchCV(clf,\n",
        "             param_grid=param_grid,\n",
        "             n_jobs=1,\n",
        "             cv=3,\n",
        "             verbose=1,\n",
        "            )\n",
        "\n",
        "model_rf_gs.fit(X,y)"
      ],
      "metadata": {
        "id": "f27tFQRMWARw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "3f69e5e4-561a-4e99-ccb6-48ede93e5378"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid parameter 'RandomForestClassifier' for estimator Pipeline(steps=[('ordinalencoder', OrdinalEncoder()),\n                ('simpleimputer', SimpleImputer()),\n                ('randomforestclassifier',\n                 RandomForestClassifier(n_jobs=-1, random_state=42))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e0b7bb6ecbbb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_rf_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mPipeline\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mlocal_valid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    206\u001b[0m                     \u001b[0;34mf\"Invalid parameter {key!r} for estimator {self}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;34mf\"Valid parameters are: {local_valid_params!r}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'RandomForestClassifier' for estimator Pipeline(steps=[('ordinalencoder', OrdinalEncoder()),\n                ('simpleimputer', SimpleImputer()),\n                ('randomforestclassifier',\n                 RandomForestClassifier(n_jobs=-1, random_state=42))]). Valid parameters are: ['memory', 'steps', 'verbose']."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPvNOV6Cw1Zl"
      },
      "source": [
        "**`RandomizedSearchCV`:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFXI-drCV9LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wT5O4MpOV4qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P_b_2u1V9II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdPydrAciFvW"
      },
      "source": [
        "# VI. Communicate Results\n",
        "\n",
        "**Showing Feature Importance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orrZCcWqj0Wu"
      },
      "source": [
        "Plot the feature importance for our `RandomForest` model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestestimator =\n",
        "importances = bestestimator.named_steps['randomforestclassifier'].feature_importances_\n",
        "features = X.columns\n",
        "feat_imp = pd.Series(importances, index=features).sort_values()\n",
        "feat_imp.tail(10).plot(kind='barh')\n",
        "plt.xlabel('Reduction in Gini Impurity');"
      ],
      "metadata": {
        "id": "X3QZfcikWWW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIiBxuSrDPZU"
      },
      "source": [
        "# VII. Make Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbEIotkT8eUM"
      },
      "source": [
        "y_pred = model_rfrs.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFL1Zdi88f98"
      },
      "source": [
        "submission = pd.DataFrame({'status_group':y_pred}, index=X_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "cNjXGaXEM9Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvrFM81t9Fqv"
      },
      "source": [
        "pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sDIlJ1fDPZW"
      },
      "source": [
        "datestamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_') #string from time format\n",
        "submission.to_csv(f'{datestamp}submission.csv') #format string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS6EDRbCbr-F"
      },
      "source": [
        "# VIII. Saving a trained model to reuse it in the future"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once you have found the best model, you might as well save it and then reload it when you want to test it later\n",
        "\n",
        "# save model\n",
        "import pickle\n",
        "\n",
        "filename =\n",
        "\n",
        "#save your model (it will be stored in your current working directory - download to your computer if GDrive is not mounted)\n",
        "pickle.dump(model_rf,open(filename,'wb'))\n",
        "#load model\n",
        "model_rf_loaded = pickle.load(open(filename,'rb'))"
      ],
      "metadata": {
        "id": "T1H0NSTQUh-A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}